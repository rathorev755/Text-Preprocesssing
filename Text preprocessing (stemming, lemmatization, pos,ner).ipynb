{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94b87207",
   "metadata": {},
   "source": [
    "# Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55e3a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f65059e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"You have my phone!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "593c60e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"phone\" in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d6ee060",
   "metadata": {},
   "outputs": [],
   "source": [
    "match = re.search(\"phone\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ec27294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 17)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4af8f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"My phone is a new phone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f47b4acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 17)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5523e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_matche = re.findall(\"phone\",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17c31b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['phone', 'phone']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_matche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "146eb4d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8)\n",
      "(18, 23)\n"
     ]
    }
   ],
   "source": [
    "for matche in re.finditer(\"phone\",text):\n",
    "    print(matche.span())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5313ba5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' cat', ' hat', ' sat', 'plat']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"..at\",\"The cat in the hat sat splat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b46a61",
   "metadata": {},
   "source": [
    "# Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96e57b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f94e6c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "55925a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.S. PROPN compound\n",
      "startup NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "6 NUM compound\n",
      "million NUM pobj\n"
     ]
    }
   ],
   "source": [
    "# Create a Doc object\n",
    "doc = nlp(u'Tesla is looking at buying U.S. startup for $6 million')\n",
    "\n",
    "# Print each token separately\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eab86f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x2025180af20>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x2025180b2e0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x2025168be60>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x202519c8340>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x20251990e00>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x2025168bed0>)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60fc36de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e670377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is AUX aux\n",
      "n't PART neg\n",
      "  SPACE dep\n",
      "looking VERB ROOT\n",
      "into ADP prep\n",
      "startups NOUN pobj\n",
      "anymore ADV advmod\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(u\"Tesla isn't  looking into startups anymore.\")\n",
    "\n",
    "for token in doc2:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46c88d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking\n",
      "look\n"
     ]
    }
   ],
   "source": [
    "# Lemmas (the base form of the word):\n",
    "print(doc2[4].text)\n",
    "print(doc2[4].lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e154c66d",
   "metadata": {},
   "source": [
    "# SPANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80ec8fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'Although commmonly attributed to John Lennon from his song \"Beautiful Boy\", \\\n",
    "the phrase \"Life is what happens to us while we are making other plans\" was written by \\\n",
    "cartoonist Allen Saunders and published in Reader\\'s Digest in 1957, when Lennon was 17.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e07a630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "life_quote = doc3[16:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c8152cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Life is what happens to us while we are making other plans\"\n"
     ]
    }
   ],
   "source": [
    "print(life_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b62a54cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u'This is the first sentence. This is another sentence. This is the last sentence.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f214d239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "for snts in doc4.sents:\n",
    "    print(snts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "29481bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4[6].is_sent_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fe48fe",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "57160d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"We're moving to L.A.!\"\n"
     ]
    }
   ],
   "source": [
    "# Create a string that includes opening and closing quotation marks\n",
    "mystring = '\"We\\'re moving to L.A.!\"'\n",
    "print(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ae1ddf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4f1088fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2db6612c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "We\n",
      "'re\n",
      "moving\n",
      "to\n",
      "L.A.\n",
      "!\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15877745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"We're moving to L.A.!\"\n"
     ]
    }
   ],
   "source": [
    "# Create a string that includes opening and closing quotation marks\n",
    "mystring = '\"We\\'re moving to L.A.!\"'\n",
    "print(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d9e696fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "5\n",
      "km\n",
      "NYC\n",
      "cab\n",
      "ride\n",
      "costs\n",
      "$\n",
      "10.30\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp(u'A 5km NYC cab ride costs $10.30')\n",
    "\n",
    "for t in doc3:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "823f8de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let\n",
      "'s\n",
      "visit\n",
      "St.\n",
      "Louis\n",
      "in\n",
      "the\n",
      "U.S.\n",
      "next\n",
      "year\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc4 = nlp(u\"Let's visit St. Louis in the U.S. next year.\")\n",
    "\n",
    "for t in doc4:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7f2ea089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cd624e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "783"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc4.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e5b5f19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "better"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc5 = nlp(u'It is better to give than to receive.')\n",
    "\n",
    "# Retrieve the third token:\n",
    "doc5[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3039a93",
   "metadata": {},
   "source": [
    "# Named Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5028af6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple | to | build | a | Hong | Kong | factory | for | $ | 6 | million | \n",
      "----\n",
      "Apple - ORG - Companies, agencies, institutions, etc.\n",
      "Hong Kong - GPE - Countries, cities, states\n",
      "$6 million - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc8 = nlp(u'Apple to build a Hong Kong factory for $6 million')\n",
    "\n",
    "for token in doc8:\n",
    "    print(token.text, end=' | ')\n",
    "\n",
    "print('\\n----')\n",
    "\n",
    "for ent in doc8.ents:\n",
    "    print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "295856f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "ORG\n",
      "Hong Kong\n",
      "GPE\n",
      "$6 million\n",
      "MONEY\n"
     ]
    }
   ],
   "source": [
    "for entity in doc8.ents:\n",
    "    print(entity)\n",
    "    print(entity.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14ab417",
   "metadata": {},
   "source": [
    "# Noun Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "14df8d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous cars\n",
      "insurance liability\n",
      "manufacturers\n"
     ]
    }
   ],
   "source": [
    "doc9 = nlp(u\"Autonomous cars shift insurance liability toward manufacturers.\")\n",
    "\n",
    "for chunk in doc9.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "29cedde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red cars\n",
      "higher insurance rates\n"
     ]
    }
   ],
   "source": [
    "doc10 = nlp(u\"Red cars do not carry higher insurance rates.\")\n",
    "\n",
    "for chunk in doc10.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b9ae1b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He\n",
      "a one-eyed, one-horned, flying, purple people-eater\n"
     ]
    }
   ],
   "source": [
    "doc11 = nlp(u\"He was a one-eyed, one-horned, flying, purple people-eater.\")\n",
    "\n",
    "for chunk in doc11.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f8709e",
   "metadata": {},
   "source": [
    "# Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6e2f2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8d9e2f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "28483e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fe4d90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['run','runner','ran','runs','easily','fairly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a18011df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-------->run\n",
      "runner-------->runner\n",
      "ran-------->ran\n",
      "runs-------->run\n",
      "easily-------->easili\n",
      "fairly-------->fairli\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + '-------->' +p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4cbac2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4b27de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_stemmer = SnowballStemmer(language = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "79d0c78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run-------->run\n",
      "runner-------->runner\n",
      "ran-------->ran\n",
      "runs-------->run\n",
      "easily-------->easili\n",
      "fairly-------->fair\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + '-------->' +s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382d98ab",
   "metadata": {},
   "source": [
    "# Lammatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0bdd0a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(u\"I am a runner running in a race because I love to run since I ran today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ac4e88a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t PRON \t 4690420944186131903 \t I\n",
      "am \t AUX \t 10382539506755952630 \t be\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "runner \t NOUN \t 12640964157389618806 \t runner\n",
      "running \t VERB \t 12767647472892411841 \t run\n",
      "in \t ADP \t 3002984154512732771 \t in\n",
      "a \t DET \t 11901859001352538922 \t a\n",
      "race \t NOUN \t 8048469955494714898 \t race\n",
      "because \t SCONJ \t 16950148841647037698 \t because\n",
      "I \t PRON \t 4690420944186131903 \t I\n",
      "love \t VERB \t 3702023516439754181 \t love\n",
      "to \t PART \t 3791531372978436496 \t to\n",
      "run \t VERB \t 12767647472892411841 \t run\n",
      "since \t SCONJ \t 10066841407251338481 \t since\n",
      "I \t PRON \t 4690420944186131903 \t I\n",
      "ran \t VERB \t 12767647472892411841 \t run\n",
      "today \t NOUN \t 11042482332948150395 \t today\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token.text,'\\t',token.pos_,'\\t',token.lemma,'\\t',token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a363d56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'latter', 'over', 'back', 'full', 'really', 'made', 'very', 'less', 'no', 'his', 'by', 'side', 'show', 'their', 'of', 'hundred', 'seeming', 'namely', 'there', 'nothing', 'through', 'becomes', 'toward', 'various', 'thru', 'this', 'my', '’re', 'whether', 'noone', \"'d\", 'rather', 'put', 'yours', 'both', 'elsewhere', 'wherein', 'nevertheless', 'during', 'third', 'sixty', 'being', '‘ve', 'fifty', 'beyond', 'sometimes', 'seems', 'at', 'indeed', 'thereafter', 'themselves', 'should', 'just', 'every', 'using', 'somewhere', 'last', 'before', 'hereafter', 'within', 'bottom', 'go', 'mine', 'under', 'seemed', 'whence', 'whereby', 'itself', 'used', 'cannot', 'hereby', 'towards', 'one', 'few', 'now', 'however', 'another', 'therefore', 'hence', 'only', 'did', 'you', 'nor', 'throughout', 'enough', 'part', 'afterwards', 'thus', 'them', '‘ll', 'does', 'beforehand', 'the', 'whither', 'most', 'yourself', 'why', '’ll', 'such', 'fifteen', 'after', 'without', 'how', 'someone', 'then', 'moreover', 'onto', 'from', 'other', '‘re', 'take', 'already', 'thereby', 'much', 'ten', 'were', 'for', 'into', 'am', 'any', 'unless', 'as', 'these', 'has', 'yourselves', 'empty', '’ve', 'besides', 'those', 'more', 'against', 'thence', 'whom', 'move', 'either', 'with', 'please', '‘m', 'give', 'former', 'amount', 'becoming', 'twelve', 'nine', 'on', 'quite', 'our', 'via', 'two', 'i', 'although', 'ca', 'amongst', 'than', 'be', 'among', 'front', 'except', \"'ve\", 'doing', 'they', 'n‘t', 'are', 'whoever', 'due', 'when', 'next', 'and', 'here', 'forty', 'that', 'name', 'eleven', 'nobody', 'somehow', 'whole', 'became', 'nowhere', 'behind', 'herein', 'done', 'everywhere', 'thereupon', \"'s\", 'become', 'because', 'regarding', 'to', \"n't\", 'your', 'ours', 'down', 'formerly', '‘d', 'together', 'mostly', 'along', 'own', 'too', 'again', 'where', 'anyway', 'himself', 'least', 'across', 'she', 'its', 'once', 'between', 'what', 'anyone', 'anything', 'twenty', 'would', 'wherever', 'well', 'him', 'out', 'a', 'it', 'above', 'otherwise', 'each', 'therein', 'four', 'serious', 'may', 'in', 'perhaps', 'which', 'anyhow', 'below', \"'ll\", 'can', 'call', '’d', '’s', 'up', \"'re\", 'whereafter', 'same', 'ourselves', 'say', 'often', 'others', 'upon', 'make', 'seem', 'all', 'if', 'been', 'three', 'keep', 'yet', 'everything', 'who', 'something', 'until', 'many', 'sometime', 'since', 'myself', 'hers', 'almost', 'still', 'per', 'had', 'her', 'everyone', '’m', 'whenever', 'some', 'else', 'whereas', 'is', 'hereupon', 'while', 'none', 'whatever', 'us', 'or', 'an', 'also', 'get', 're', 'have', 'always', 'several', 'further', '‘s', 'beside', 'must', 'though', 'not', 'anywhere', 'even', 'was', 'neither', 'latterly', 'so', 'whereupon', 'five', 'n’t', 'might', 'could', 'alone', 'never', 'but', 'me', 'off', 'see', 'first', 'six', 'about', 'do', 'meanwhile', 'eight', 'will', 'ever', \"'m\", 'he', 'around', 'herself', 'we', 'whose', 'top'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8b35c613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5195fe2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "822"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "88070eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words.remove('beyond')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "56e32615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['beyond'].is_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00104389",
   "metadata": {},
   "source": [
    "# Pat of Speech "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "695873ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"The quick brown fox jumped over the lazy dog's back.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fb434099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox jumped over the lazy dog's back.\n"
     ]
    }
   ],
   "source": [
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8684ae00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumped\n"
     ]
    }
   ],
   "source": [
    "print(doc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a8c9d843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERB\n"
     ]
    }
   ],
   "source": [
    "print(doc[4].pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "83f0ecaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VBD\n"
     ]
    }
   ],
   "source": [
    "print(doc[4].tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d2f2eb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The         DET        DT         determiner\n",
      "quick       ADJ        JJ         adjective (English), other noun-modifier (Chinese)\n",
      "brown       ADJ        JJ         adjective (English), other noun-modifier (Chinese)\n",
      "fox         NOUN       NN         noun, singular or mass\n",
      "jumped      VERB       VBD        verb, past tense\n",
      "over        ADP        IN         conjunction, subordinating or preposition\n",
      "the         DET        DT         determiner\n",
      "lazy        ADJ        JJ         adjective (English), other noun-modifier (Chinese)\n",
      "dog         NOUN       NN         noun, singular or mass\n",
      "'s          PART       POS        possessive ending\n",
      "back        NOUN       NN         noun, singular or mass\n",
      ".           PUNCT      .          punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f\"{token.text:{10}}  {token.pos_:{10}} {token.tag_:{10}} {spacy.explain(token.tag_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b66d0dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ents(doc):\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text+ ' _ ' +ent.label_+ ' _ '+str(spacy.explain(ent.label_)))\n",
    "    else:\n",
    "        print(\"no entities found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cae85ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Hi how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f93301d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no entities found\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fb78c14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"May I go to Wahington, DC next May to see the Washington Monument?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "330395b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wahington, DC _ GPE _ Countries, cities, states\n",
      "next May _ DATE _ Absolute or relative dates or periods\n",
      "the Washington Monument _ ORG _ Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "693a907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Our Campany created a brand new vacuum cleaner.\"\n",
    "         U\"This new vacuum-cleaner is the best in show.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0d56e6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no entities found\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "58e75744",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "551f18f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
